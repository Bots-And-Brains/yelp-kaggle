{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validate data: 400\n",
      "validate labels:400\n",
      "train data:1600\n",
      "train labels:1600\n",
      "test data:1911\n",
      "test business ids:1911\n",
      "{'train_labels': matrix([[ 1.,  1.,  0., ...,  0.,  0.,  0.],\n",
      "        [ 1.,  1.,  1., ...,  0.,  0.,  0.],\n",
      "        [ 1.,  1.,  1., ...,  0.,  0.,  0.],\n",
      "        ..., \n",
      "        [ 1.,  1.,  1., ...,  0.,  0.,  0.],\n",
      "        [ 1.,  1.,  1., ...,  0.,  0.,  0.],\n",
      "        [ 1.,  0.,  0., ...,  0.,  0.,  0.]], dtype=float16), 'validate_data': matrix([[ 3.38476562,  5.515625  ,  1.61035156, ...,  6.04296875,\n",
      "          4.328125  ,  3.33984375],\n",
      "        [ 3.02929688,  1.91699219,  0.13842773, ...,  1.87890625,\n",
      "          0.41894531,  3.9453125 ],\n",
      "        [ 3.83789062,  6.30078125,  2.68359375, ...,  1.96777344,\n",
      "          3.40820312,  2.09960938],\n",
      "        ..., \n",
      "        [ 3.75      ,  3.609375  ,  0.47729492, ...,  8.6953125 ,\n",
      "          2.00976562,  4.046875  ],\n",
      "        [ 5.3828125 ,  7.34375   ,  1.04785156, ...,  2.34179688,\n",
      "          3.6953125 ,  2.08789062],\n",
      "        [ 4.60546875,  0.82958984,  0.72460938, ...,  5.81640625,\n",
      "          0.04830933,  1.16699219]], dtype=float16), 'test_business_ids': Index([u'003sg', u'00er5', u'00kad', u'00mc6', u'00q7x', u'00v0t', u'00y7p',\n",
      "       u'019fg', u'019r1', u'01i5j',\n",
      "       ...\n",
      "       u'6tiwr', u'6tk8y', u'6tkch', u'6tpq3', u'6tu39', u'6u1yf', u'6u8qq',\n",
      "       u'6ud41', u'6uko9', u'6v4w3'],\n",
      "      dtype='object', name=u'business_id', length=1911), 'test_data': matrix([[  4.66796875,   6.21484375,   2.5234375 , ...,   8.21875   ,\n",
      "          13.3046875 ,   7.67578125],\n",
      "        [  4.61328125,   8.59375   ,   3.22851562, ...,   7.03125   ,\n",
      "           6.79296875,   4.46484375],\n",
      "        [  4.75      ,   4.3203125 ,   2.47265625, ...,   7.9375    ,\n",
      "           7.66015625,   4.8828125 ],\n",
      "        ..., \n",
      "        [  4.296875  ,   4.546875  ,   1.70410156, ...,   5.7890625 ,\n",
      "           5.1796875 ,   4.58203125],\n",
      "        [  5.0078125 ,   5.234375  ,   1.34667969, ...,   3.90820312,\n",
      "           3.79882812,   6.796875  ],\n",
      "        [  4.73828125,   4.77734375,   1.09082031, ...,   5.265625  ,\n",
      "           6.21875   ,   3.        ]], dtype=float16), 'validate_labels': matrix([[ 1.,  1.,  1., ...,  0.,  0.,  0.],\n",
      "        [ 1.,  1.,  1., ...,  1.,  0.,  0.],\n",
      "        [ 1.,  1.,  1., ...,  0.,  0.,  0.],\n",
      "        ..., \n",
      "        [ 1.,  1.,  1., ...,  0.,  0.,  0.],\n",
      "        [ 1.,  1.,  1., ...,  0.,  0.,  0.],\n",
      "        [ 1.,  1.,  1., ...,  0.,  0.,  0.]], dtype=float16), 'train_data': matrix([[  6.2109375 ,   1.68554688,   2.2421875 , ...,   5.984375  ,\n",
      "           2.64453125,   3.72070312],\n",
      "        [  5.25390625,   5.046875  ,   2.48828125, ...,   6.39453125,\n",
      "           8.03125   ,   5.640625  ],\n",
      "        [  6.1484375 ,   9.0234375 ,   3.37890625, ...,   9.1875    ,\n",
      "          11.6953125 ,   5.5234375 ],\n",
      "        ..., \n",
      "        [  2.94921875,   4.578125  ,   3.703125  , ...,   2.609375  ,\n",
      "           2.49023438,   3.62304688],\n",
      "        [  4.16015625,   7.5       ,   2.8203125 , ...,   4.97265625,\n",
      "           7.36328125,   5.703125  ],\n",
      "        [  3.85351562,   2.8046875 ,   2.20703125, ...,   4.74609375,\n",
      "           2.10742188,   5.05078125]], dtype=float16)}\n"
     ]
    }
   ],
   "source": [
    "# Goal - convert features and labels from dataframes to np arrays ready for use in tensorflow.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "\n",
    "tf_output = {}\n",
    "\n",
    "# Load the cached pandas pickle file.\n",
    "base_dir = '../data/'\n",
    "\n",
    "# Load validation set dataframe from file\n",
    "feat_validate_df = pd.read_pickle(base_dir + 'feat_validate.pickle')\n",
    "# Group the data by taking the max of all images per business\n",
    "biz_feat_validate_df= feat_validate_df.groupby(['business_id']).agg(['max'])\n",
    "# Drop photo_id, since all ids were averaged (And we don't care about it anyways)\n",
    "biz_feat_validate_df.drop('photo_id', axis=1, inplace=True)\n",
    "# Grab the (already sorted) business_ids to be used to split the labels up.\n",
    "biz_ids_validate = biz_feat_validate_df.index\n",
    "\n",
    "# See above for details.\n",
    "feat_train_df = pd.read_pickle(base_dir + 'feat_train.pickle')\n",
    "biz_feat_train_df= feat_train_df.groupby(['business_id']).agg(['max'])\n",
    "biz_feat_train_df.drop('photo_id', axis=1, inplace=True)\n",
    "biz_ids_train = biz_feat_train_df.index\n",
    "\n",
    "# See above for details.\n",
    "feat_test_df = pd.read_pickle(base_dir + 'features_test.pickle')\n",
    "biz_feat_test_df= feat_test_df.groupby(['business_id']).agg(['max'])\n",
    "biz_feat_test_df.drop('photo_id', axis=1, inplace=True)\n",
    "biz_ids_test = biz_feat_test_df.index\n",
    "\n",
    "\n",
    "#Clean up labels\n",
    "labels_df = pd.read_pickle(base_dir + 'labels.pickle')\n",
    "# Make the index int64 instead of string so sorting and matching works correctly.\n",
    "labels_df.index = pd.to_numeric(labels_df.index)\n",
    "# Sort all the labels based on business_id\n",
    "labels_df = labels_df.sort_index()\n",
    "\n",
    "tf_output['validate_data'] = np.matrix(biz_feat_validate_df)\n",
    "tf_output['validate_labels'] = np.matrix(labels_df[labels_df.index.isin(biz_ids_validate)], dtype='float16')\n",
    "tf_output['train_data'] = np.matrix(biz_feat_train_df)\n",
    "tf_output['train_labels'] = np.matrix(labels_df[labels_df.index.isin(biz_ids_train)], dtype='float16')\n",
    "tf_output['test_data'] = np.matrix(biz_feat_test_df)\n",
    "tf_output['test_business_ids'] = biz_ids_test\n",
    "\n",
    "\n",
    "print \"validate data: \" + str(len(tf_output['validate_data']))\n",
    "print \"validate labels:\" + str(len(tf_output['validate_labels']))\n",
    "print \"train data:\" + str(len(tf_output['train_data']))\n",
    "print \"train labels:\" + str(len(tf_output['train_labels']))\n",
    "print \"test data:\" + str(len(tf_output['test_data']))\n",
    "print \"test business ids:\" + str(len(tf_output['test_business_ids']))\n",
    "\n",
    "print tf_output\n",
    "\n",
    "output_file = open(base_dir + \"tf_data.pickle\", 'wb')\n",
    "pickle.dump(tf_output, output_file)\n",
    "output_file.close()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
