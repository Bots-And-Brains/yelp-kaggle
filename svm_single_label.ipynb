{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "import pickle\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.utils import multiclass as mc\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.preprocessing import MultiLabelBinarizer, scale\n",
    "from lib import accuracy\n",
    "from lib import labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set (1600, 1024) (1600, 9)\n",
      "Validation set (400, 1024) (400, 9)\n",
      "Test set (10000, 1024) 10000\n"
     ]
    }
   ],
   "source": [
    "data_dir = \"../data/\"\n",
    "pickle_file = 'tf_data_max.pickle'\n",
    "\n",
    "with open(data_dir + pickle_file, 'rb') as f:\n",
    "    save = pickle.load(f)\n",
    "    train_dataset = np.matrix(save['train_data'], dtype='float32')\n",
    "    train_labels = np.matrix(save['train_labels'], dtype='float32')\n",
    "    valid_dataset = np.matrix(save['validate_data'], dtype='float32')\n",
    "    valid_labels = np.matrix(save['validate_labels'], dtype='float32')\n",
    "    test_dataset = np.matrix(save['test_data'], dtype='float32')\n",
    "    test_bids = list(save['test_business_ids'])\n",
    "    #test_bids = np.ravel(test_bids)\n",
    "    del save  # hint to help gc free up memory\n",
    "    print 'Training set', train_dataset.shape, train_labels.shape\n",
    "    print 'Validation set', valid_dataset.shape, valid_labels.shape\n",
    "    print 'Test set', test_dataset.shape, len(test_bids)\n",
    "\n",
    "# Convert labels to a dict of binarized labels [1. if true, 1. if false]\n",
    "# So can be used for softmax per label.\n",
    "train_labels = labels.binarize_softmax_labels(train_labels)\n",
    "valid_labels = labels.binarize_softmax_labels(valid_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#0: 73.00\n",
      "#1: 80.50\n",
      "#2: 84.00\n",
      "#3: 62.25\n",
      "#4: 84.50\n",
      "#5: 83.50\n",
      "#6: 88.25\n",
      "#7: 83.25\n",
      "#8: 84.00\n"
     ]
    }
   ],
   "source": [
    "# Disabled scaling because it seems to make it always a little worse!\n",
    "scaled_train = train_dataset #scale(train_dataset)\n",
    "scaled_valid = valid_dataset #scale(valid_dataset)\n",
    "svm_preds = np.zeros((400, 9), dtype=\"float32\")\n",
    "svm_test_preds = np.zeros((test_dataset.shape[0], 9), dtype=\"float32\")\n",
    "\n",
    "for i in range(9):\n",
    "    label_n = i\n",
    "    trainL = labels.matrix_2_labels(train_labels[label_n])\n",
    "\n",
    "    trainL = MultiLabelBinarizer().fit_transform(trainL)\n",
    "    #train_labels = matrix_2_labels(train_labels)\n",
    "    trainL = np.asarray(trainL)\n",
    "\n",
    "    #clf = svm.SVC(decision_function_shape='ovr', kernel='linear')\n",
    "    \n",
    "\n",
    "    clf = OneVsRestClassifier(svm.LinearSVC(random_state=42)).fit(scaled_train, trainL)\n",
    "    predictions = clf.predict(scaled_valid)\n",
    "    test_predictions = clf.predict(test_dataset)\n",
    "    print \"#\"+str(i)+\": {0:.2f}\".format(accuracy.binarized_accuracy(predictions, valid_labels[label_n]) * 100)\n",
    "    svm_preds[:,i] = predictions[:,0]\n",
    "    svm_test_preds[:,i] = test_predictions[:,0]\n",
    "\n",
    "with open(data_dir+\"svm_test_preds.pickle\", 'wb') as f:\n",
    "    # Pickle dictionary using protocol 0.\n",
    "    pickle.dump(svm_test_preds, f)\n",
    "#0: good_for_lunch\n",
    "#1: good_for_dinner\n",
    "#2: takes_reservations\n",
    "#3: outdoor_seating\n",
    "#4: restaurant_is_expensive\n",
    "#5: has_alcohol\n",
    "#6: has_table_service\n",
    "#7: ambience_is_classy\n",
    "#8: good_for_kids    \n",
    "    \n",
    "    \n",
    "# svm.LinearSVC(random_state=0)\n",
    "#SVM by label (mean)\n",
    "#0: 72.25\n",
    "#1: 79.50\n",
    "#2: 82.75\n",
    "#3: 62.50\n",
    "#4: 84.25\n",
    "#5: 83.75\n",
    "#6: 88.5\n",
    "#7: 83.25\n",
    "#8: 83.75\n",
    "\n",
    "# svm.LinearSVC(random_state=0)\n",
    "#SVM by label (max)\n",
    "#0: 66.25\n",
    "#1: 78.75\n",
    "#2: 83.75\n",
    "#3: 59.50\n",
    "#4: 83.50\n",
    "#5: 84.25\n",
    "#6: 87.50\n",
    "#7: 78.25\n",
    "#8: 78.75\n",
    "\n",
    "# Best DNN Model (current)\n",
    "# 2 Hidden Layer model with L2 regularization added to the loss, and 20% dropout.\n",
    "# AdaGradOptimizer\n",
    "# regularizer = 1e-8\n",
    "# training_rate = 0.5\n",
    "# num_steps = 3000 (more steps could have more improvement!)\n",
    "#0: 77.75%\n",
    "#1: 84.50\n",
    "#2: 86.50\n",
    "#3: 59.25\n",
    "#4: 86.50\n",
    "#5: 87.25\n",
    "#6: 92.00\n",
    "#7: 84.00\n",
    "#8: 86.00\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 9)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_test_preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
