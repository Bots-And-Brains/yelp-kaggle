{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "# Load the cached pandas pickle file.\n",
    "base_dir = '../data/'\n",
    "features = pd.read_pickle(base_dir + 'features.pickle')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400\n",
      "1600\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "train_data = pd.read_csv('../data/train.csv')\n",
    "X_train, X_validate = train_test_split(train_data.business_id, test_size=0.2, random_state=42)\n",
    "\n",
    "print len(X_validate)\n",
    "print len(X_train)\n",
    "\n",
    "feat_validate = features[features.business_id.isin(X_validate)]\n",
    "feat_train = features[features.business_id.isin(X_train)]\n",
    "feat_validate.to_pickle(base_dir + 'feat_validate.pickle')\n",
    "feat_train.to_pickle(base_dir + 'feat_train.pickle')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3.38476562  5.515625    1.61035156 ...,  6.04296875  4.328125\n",
      "   3.33984375]\n",
      " [ 3.02929688  1.91699219  0.13842773 ...,  1.87890625  0.41894531\n",
      "   3.9453125 ]\n",
      " [ 3.83789062  6.30078125  2.68359375 ...,  1.96777344  3.40820312\n",
      "   2.09960938]\n",
      " ..., \n",
      " [ 3.75        3.609375    0.47729492 ...,  8.6953125   2.00976562\n",
      "   4.046875  ]\n",
      " [ 5.3828125   7.34375     1.04785156 ...,  2.34179688  3.6953125\n",
      "   2.08789062]\n",
      " [ 4.60546875  0.82958984  0.72460938 ...,  5.81640625  0.04830933\n",
      "   1.16699219]]\n"
     ]
    }
   ],
   "source": [
    "feat_validate = pd.read_pickle(base_dir + 'feat_validate.pickle')\n",
    "feat_train = pd.read_pickle(base_dir + 'feat_train.pickle')\n",
    "\n",
    "#biz_feat_train = feat_train.groupby(['business_id']).agg(['max'])\n",
    "#biz_feat_train.drop('photo_id', axis=1, inplace=True)\n",
    "#print biz_feat_train.values()\n",
    "\n",
    "biz_feat_validate = feat_validate.groupby(['business_id']).agg(['max'])\n",
    "biz_feat_validate.drop('photo_id', axis=1, inplace=True)\n",
    "print np.matrix(biz_feat_validate.values)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
      "Index: []\n",
      "1 2 4 5 6 7\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "# Load the cached pandas pickle file.\n",
    "base_dir = '../data/'\n",
    "features = pd.read_pickle(base_dir + 'features.pickle')\n",
    "\n",
    "\n",
    "labels_file = os.path.join(os.curdir,\"../data/train.csv\")\n",
    "l = np.loadtxt(labels_file, dtype=np.dtype('string'), delimiter=\",\",skiprows=1)\n",
    "biz2labels = dict([(x[0],x[1].split()) for x in l])\n",
    "biz_labels_df = pd.DataFrame.from_dict(biz2labels, orient='index', dtype='bool')\n",
    "biz_labels_df.to_pickle(base_dir + 'labels.pickle')\n",
    "biz_ids = biz_labels_df.index\n",
    "labels = np.matrix(biz_labels_df, dtype='float16')\n",
    "\n",
    "#Split the labels into train and validate sets as well.\n",
    "train_labels = biz_labels_df[biz_labels_df.index.isin(X_train)]\n",
    "validate_labels = biz_labels_df[biz_labels_df.index.isin(X_validate)]\n",
    "print validate_labels\n",
    "\n",
    "\n",
    "biz_feat_validate = feat_validate.groupby(['business_id']).agg(['max'])\n",
    "biz_feat_validate.drop('photo_id', axis=1, inplace=True)\n",
    "for i in range(len(biz_feat_validate)):\n",
    "    biz_id = biz_feat_validate.index[i]\n",
    "    biz = train_data.loc[(train_data['business_id'] == biz_id)]\n",
    "    print biz['labels'].values[0]\n",
    "\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_dataset = save['train_dataset']\n",
    "train_labels = save['train_labels']\n",
    "valid_dataset = save['valid_dataset']\n",
    "valid_labels = save['valid_labels']\n",
    "test_dataset = save['test_dataset']\n",
    "test_labels = save['test_labels']\n",
    "del save  # hint to help gc free up memory\n",
    "print 'Training set', train_dataset.shape, train_labels.shape\n",
    "print 'Validation set', valid_dataset.shape, valid_labels.shape\n",
    "print 'Test set', test_dataset.shape, test_labels.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
